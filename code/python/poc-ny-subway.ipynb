{"cells":[{"cell_type":"code","source":["from pyspark import *\nfrom pyspark.sql.functions import *\nfrom pyspark.ml.feature import StringIndexer\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.feature import Bucketizer\nfrom pyspark.ml.stat import Correlation\nfrom pyspark.ml.linalg import Vectors\nfrom pyspark.mllib.stat import Statistics\n\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":1},{"cell_type":"markdown","source":["# Exploratory data analysis (EDA)"],"metadata":{}},{"cell_type":"code","source":["# Carrega dataset do desafio (basta descompactar todos na mesma pasta)\n#display(dbutils.fs.ls(\"dbfs:/FileStore/tables/\"))\ndf_desafio = spark.read.format(\"csv\").options(header='true').load(\"/FileStore/tables/*.csv\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"code","source":["# Elimina na's e duplicados do df\ndf_desafio_v2 = df_desafio.dropna(how='any').dropDuplicates()\n\n# Ajusta tipo de colunas\ndf_desafio_v2 = df_desafio_v2.selectExpr(\n  'cast(time as timestamp) time',\n  'ca',\n  'unit',\n  'scp',\n  'station',\n  'linename',\n  'division',\n  'desc',\n  'cast(entries as int) entries',\n  'cast(exits as int) exits'\n)\n\n# Features para visão temporal\ndf_desafio_v2 = df_desafio_v2.withColumn(\n  \"dt_year\",\n  year(col(\"time\"))\n).withColumn(\n  \"dt_month\",\n  month(col(\"time\"))\n).withColumn(\n  \"dt_day\",\n  dayofmonth(col(\"time\"))\n).withColumn(\n  \"dt_dayofy\",\n  dayofyear(col(\"time\"))  \n).withColumn(\n  \"dt_hour\",\n  hour(col(\"time\"))\n).withColumn(\n  \"dt_min\",\n  minute(col(\"time\"))\n).withColumn(\n  \"dt_week_no\",\n  weekofyear(col(\"time\"))\n).withColumn(\n  \"dt_int\",\n  unix_timestamp(col(\"time\"))\n).withColumn(\n  \"dt_month_year\",\n  date_format(col(\"time\"), \"Y-MM\")\n)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":4},{"cell_type":"code","source":["# Intervalos para buckets\nsplits = [-30000000, -20000000, -10000000, 0.0, 10000000, 20000000, 30000000]\n\n# ===> Bucket: 'entries'\n# dataFrame = df_desafio_v2.select(col('entries'))\n# bucketizer = Bucketizer(splits=splits, inputCol=\"entries\", outputCol=\"bucketedFeatures\")\n# bucketedData_entries = bucketizer.transform(dataFrame)\n# sorted(bucketedData_entries.groupBy(\"bucketedFeatures\").count().collect())\n# [Row(bucketedFeatures=0.0, count=15721),\n#  Row(bucketedFeatures=1.0, count=4028),\n#  Row(bucketedFeatures=2.0, count=496),\n#  Row(bucketedFeatures=4.0, count=71457425), ==> Begin\n#  Row(bucketedFeatures=5.0, count=5052549),  <== End\n#  Row(bucketedFeatures=6.0, count=278162),\n#  Row(bucketedFeatures=7.0, count=2237294)]\n\n# ===> Bucket: 'exits'\n# dataFrame = df_desafio_v2.select(col('exits'))\n# bucketizer = Bucketizer(splits=splits, inputCol=\"exits\", outputCol=\"bucketedFeatures\")\n# bucketedData_exits = bucketizer.transform(dataFrame)\n# sorted(bucketedData_exits.groupBy(\"bucketedFeatures\").count().collect())\n# [Row(bucketedFeatures=0.0, count=30576),\n#  Row(bucketedFeatures=2.0, count=576),\n#  Row(bucketedFeatures=3.0, count=1),\n#  Row(bucketedFeatures=4.0, count=73751241), ==> Begin\n#  Row(bucketedFeatures=5.0, count=3698911),  <== End\n#  Row(bucketedFeatures=6.0, count=413740),\n#  Row(bucketedFeatures=7.0, count=1150630)]\n\n# Parâmetros para filtros de outliers\noutlier_begin = 0\noutlier_end = 20000000\n\ndf_desafio_v2 = df_desafio_v2.where((col('entries')>=outlier_begin) & (col('entries')<=outlier_end) & (col('exits')>=outlier_begin) & (col('exits')<=outlier_end))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"code","source":["# Check: 79.609.191 / 79.130.015 / 79.045.675 / 75.923.980\ncount_desafio = df_desafio.count()\ncount_desafio_na = df_desafio.dropna(how='any').count()\ncount_desafio_final = df_desafio.dropna(how='any').dropDuplicates().count()\ncount_desafio_outliers = df_desafio_v2.count()\n\ndf_amostras = sc.parallelize([\n  ('antes',count_desafio,0,0,0,0),\n  ('depois',0,count_desafio_final,count_desafio-count_desafio_na,count_desafio_na-count_desafio_final,count_desafio_final-count_desafio_outliers)\n]).toDF(['AMOSTRAS','TOTAL','UNICO','NA','DUPLICADO','OUTLIERS'])\n\ndisplay(df_amostras)"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["df_amostras_v2 = sc.parallelize([\n  ('',count_desafio-count_desafio_na,count_desafio_na-count_desafio_final,count_desafio_final-count_desafio_outliers)\n]).toDF(['AMOSTRAS','NA','DUPLICADO','OUTLIERS'])\n\ndisplay(df_amostras_v2)"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["# Método para variáveis categóricas (dummys) ~14.59 minutes\nlista_idx = ['ca', 'unit', 'scp', 'station', 'linename', 'division', 'desc']\nindexers = [StringIndexer(inputCol=column,outputCol=column+\"_idx\").fit(df_desafio_v2) for column in lista_idx]\npipeline = Pipeline(stages=indexers)\ndf_desafio_v2 = pipeline.fit(df_desafio_v2).transform(df_desafio_v2)\n#display(df_desafio_v2)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":8},{"cell_type":"code","source":["df_desafio_num = df_desafio_v2.select(\n  'entries','exits','dt_year','dt_month','dt_day','dt_dayofy',\n  'dt_hour','dt_min','dt_week_no','dt_int','ca_idx','unit_idx',\n  'scp_idx','station_idx','linename_idx','division_idx','desc_idx'\n)\n\ncol_names = df_desafio_num.columns\nfeatures = df_desafio_num.rdd.map(lambda row: row[0:])\ncorr_mat = Statistics.corr(features, method=\"pearson\")\ncorr_df = pd.DataFrame(corr_mat)\ncorr_df.index, corr_df.columns = col_names, col_names\ncorr_df\n#Falta gráfico"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":9},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["#df_graficos = df_desafio_v2.filter(col('dt_year')=='2017')\ndf_graficos = df_desafio_v2.groupBy(\n  'dt_month_year',\n  'dt_year',\n  'dt_month',\n  'dt_day',\n  'dt_hour'\n).agg(\n  sum('entries'),\n  sum('exits')\n).orderBy(\n  \"dt_month_year\"\n).toPandas()"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["#display(df_graficos)"],"metadata":{},"outputs":[],"execution_count":12}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.6.5","nbconvert_exporter":"python","file_extension":".py"},"name":"poc-ny-subway","notebookId":1932292055738400},"nbformat":4,"nbformat_minor":0}
