{"cells":[{"cell_type":"code","source":["from pyspark import *\nfrom pyspark.sql.functions import *"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":1},{"cell_type":"markdown","source":["# Exploratory data analysis (EDA)"],"metadata":{}},{"cell_type":"code","source":["# Dataset original\n#display(dbutils.fs.ls(\"dbfs:/FileStore/tables/\"))\ndf_desafio = spark.read.format(\"csv\").options(header='true').load(\"/FileStore/tables/*.csv\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"code","source":["# Elimina na's e duplicados do df\ndf_desafio_v2 = df_desafio.dropna(how='any').dropDuplicates()\n\n# Ajusta tipo de colunas\ndf_desafio_v2 = df_desafio.selectExpr(\n  'cast(time as timestamp) time',\n  'ca',\n  'unit',\n  'scp',\n  'station',\n  'linename',\n  'division',\n  'desc',\n  'cast(entries as int) entries',\n  'cast(exits as int) exits'\n)\n\n# Temporal Features\ndf_desafio_v2 = df_desafio_v2.withColumn(\n  \"dt_year\",\n  year(col(\"time\"))\n).withColumn(\n  \"dt_month\",\n  month(col(\"time\"))\n).withColumn(\n  \"dt_day\",\n  dayofmonth(col(\"time\"))\n).withColumn(\n  \"dt_dayofy\",\n  dayofyear(col(\"time\"))\n).withColumn(\n  \"dt_hour\",\n  hour(col(\"time\"))\n).withColumn(\n  \"dt_min\",\n  minute(col(\"time\"))\n).withColumn(\n  \"dt_week_no\",\n  weekofyear(col(\"time\"))\n).withColumn(\n  \"dt_int\",\n  unix_timestamp(col(\"time\"))\n)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":4},{"cell_type":"code","source":["#79609191 / 79130015 / 79045675\ncount_desafio = df_desafio.count()\ncount_desafio_na = df_desafio.dropna(how='any').count()\ncount_desafio_final = df_desafio.dropna(how='any').dropDuplicates().count()\n\ndf_amostras = sc.parallelize([\n  ('antes',count_desafio,0,0,0),\n  ('depois',0,count_desafio_final,count_desafio-count_desafio_na,count_desafio_na-count_desafio_final)\n]).toDF(['AMOSTRAS','TOTAL','UNICO','NA','DUPLICADO'])\n\ndisplay(df_amostras)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>AMOSTRAS</th><th>TOTAL</th><th>UNICO</th><th>NA</th><th>DUPLICADO</th></tr></thead><tbody><tr><td>antes</td><td>79609191</td><td>0</td><td>0</td><td>0</td></tr><tr><td>depois</td><td>0</td><td>79045675</td><td>479176</td><td>84340</td></tr></tbody></table></div>"]}}],"execution_count":5},{"cell_type":"code","source":["df_amostras_v2 = sc.parallelize([\n  ('',count_desafio-count_desafio_na,count_desafio_na-count_desafio_final)\n]).toDF(['AMOSTRAS','NA','DUPLICADO'])\n\ndisplay(df_amostras_v2)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>AMOSTRAS</th><th>NA</th><th>DUPLICADO</th></tr></thead><tbody><tr><td></td><td>479176</td><td>84340</td></tr></tbody></table></div>"]}}],"execution_count":6},{"cell_type":"code","source":["# Infos do dataset\ndisplay(df_desafio_v2)"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["display(df_desafio_v2.groupBy(df_desafio_v2.columns).count())"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["pivot_cols = ['ca']\nkeys = ['time','ca']\n\nbefore = df_desafio_v2 \n\n#Helper function to recursively join a list of dataframes\n#Can be simplified if you only need two columns\ndef join_all(dfs,keys):\n    if len(dfs) > 1:\n        return dfs[0].join(join_all(dfs[1:],keys), on = keys, how = 'inner')\n    else:\n        return dfs[0]\n\ndfs = []\ncombined = []\nfor pivot_col in pivot_cols:\n    pivotDF = before.groupBy(keys).pivot(pivot_col).count()\n    new_names = pivotDF.columns[:len(keys)] +  [\"e_{0}_{1}\".format(pivot_col, c) for c in pivotDF.columns[len(keys):]]        \n    df = pivotDF.toDF(*new_names).fillna(0)    \n    combined.append(df)\n\njoin_all(combined,keys).show()"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["display(join_all(combined,keys))"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":["### Convert features to Categorical"],"metadata":{}},{"cell_type":"code","source":["ca = df_desafio_v2.select(\"ca\").distinct().rdd.flatMap(lambda x: x).collect()\nca_expr = [F.when(F.col(\"ca\") == ty, 1).otherwise(0).alias(\"e_ca_\" + ty) for ty in ca]\n\ndisplay(df_desafio_v2.select(\"ca\", *ca_expr))"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["display(df_desafio_v2.select(\"ca\", *ca_expr))"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["df_v2.info()"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["# Resumo de cada feature\nfor coluna in df_v2.columns:\n    print(df_v2[coluna].describe())\n    print('\\n\\n')"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":["### Histogram"],"metadata":{}},{"cell_type":"code","source":["df_hist = df_v2.sort_index(axis=1)"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["df_hist.hist(figsize=(20, 20), bins=50, xlabelsize=8, ylabelsize=8);"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":["### Correlation"],"metadata":{}},{"cell_type":"code","source":["corr = df_v2.corr()\nplt.figure(figsize=(11, 9))\n\n# Mask for the upper triangle\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n# Figure\nf, ax = plt.subplots(figsize=(11, 9))\n\n# Colormap\ncmap = sns.diverging_palette(10, 220, as_cmap=True)\n\nsns.heatmap(corr, \n            cmap=cmap, \n            mask=mask,\n            vmax=.3,             \n            linewidths=.5,\n            center=0,\n            annot=True, \n            annot_kws={\"size\": 8}, \n            square=True, \n            cbar_kws={\"shrink\": .5});"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["# Tabela de correlação\ncorr"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":["### Linear Regression - entries/exits  vs feature"],"metadata":{}},{"cell_type":"code","source":["df_v3 = df_v2\ny_list = ['entries','exits']\n\nfor y in y_list:\n    fig, ax = plt.subplots(round(len(df_v3.columns) / 3), 3, figsize = (20, 20))\n\n    for i, ax in enumerate(fig.axes):\n        if i < len(df_v3.columns) - 1:        \n            sns.regplot(x=df_v3[df_v3.columns[i]],y=y, data=df_v3, ax=ax).set_title(\"LR for '\"+y+\"' vs \"+df_v3.columns[i])"],"metadata":{"scrolled":true},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":["### Underfitting vs. Overfitting"],"metadata":{}},{"cell_type":"code","source":["# X = df_v2\n# y = df_v2['entries']\n\n# polynomial_features = PolynomialFeatures(degree=1, include_bias=False)\n# linear_regression = linear_model.LinearRegression()\n# pipeline = Pipeline([(\"polynomial_features\", polynomial_features),\n#                      (\"linear_regression\", linear_regression)])\n# pipeline.fit(X, y)\n\n# # Evaluate the models using crossvalidation\n# scores = cross_val_score(pipeline, X, y, scoring=\"neg_mean_squared_error\", cv=10)\n\n# X_test = X[['ca', 'unit', 'scp', 'station', 'linename', 'division', 'desc', 'exits', 'year', 'month', 'day', 'hour']]\n# plt.plot(X_test, pipeline.predict(X_test), label=\"Model\")\n# # plt.plot(X_test, X_test, label=\"True function\")\n# plt.scatter(X, y, edgecolor='b', s=20, label=\"Samples\")\n# plt.xlabel(\"x\")\n# plt.ylabel(\"y\")\n# plt.xlim((0, 1))\n# plt.ylim((-2, 2))\n# plt.legend(loc=\"best\")\n# plt.show()"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":["### Outlier Detection"],"metadata":{}},{"cell_type":"code","source":["# rng = np.random.RandomState(42)\n# clf = ensemble.IsolationForest(max_samples=100, random_state=rng)\n# clf.fit(df_v2)"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"markdown","source":["# Model Selection"],"metadata":{}},{"cell_type":"code","source":["# Dataset para model selection\ndf_ms = df_v2.copy()\n\n# Predict Y\ndel df_ms['entries']\nY = df_v2['entries']\n\n# List of results\nresultados = [['status','model','mean','std','time']]\n\n# Model selection - Score\nfor var in modelos:\n    start = time.time()\n    try:\n        print(var)\n        clf = var()\n        scores = cross_val_score(clf, df_ms, Y, cv=10)\n        print('Mean score: ',np.mean(scores), '/ Std Score: ',np.std(scores))\n        resultados.append(['ok',var.__name__,np.mean(scores),np.std(scores),time.time() - start])\n    except(Exception):\n        print('>> Validar parâmetros.')\n        resultados.append(['erro',var.__name__,None,None,time.time() - start])\n        pass\n    finally:            \n        print('-'*100)"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"markdown","source":["### Create XLS to results"],"metadata":{}},{"cell_type":"code","source":["writer = pd.ExcelWriter('/dbfs/FileStore/tables/resultados_modelos.xlsx', engine='xlsxwriter')\ndf_result = pd.DataFrame(resultados[1:])\ndf_result.columns = resultados[0]\ndf_result.to_excel(writer, sheet_name='Sheet1', index=False)\nwriter.save()"],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"markdown","source":["### Fit Model"],"metadata":{}},{"cell_type":"code","source":["# Seleciona o melhor modelo\ndf_result = df_result.sort_values(by='mean', ascending=False)\nmodel_selected = pd.Series.tolist(df_result[:1]['model'])\n# model_selected[0]\n\n# Fit do modelo\n# for item in modelos:\n#     if str(item).find(model_selected[0]) > 0:\n#         model_result = item.fit(X=df_ms,y=Y)\n\nmodel_result = ensemble.GradientBoostingRegressor().fit(X=df_ms,y=Y)"],"metadata":{},"outputs":[],"execution_count":33},{"cell_type":"code","source":["# Ajuste para próximo ano\ndf_mp = df_ms.copy()\ndf_mp['year'] = df_mp['year']+1\n\ndf_mp['entries_new'] = list(map(int,model_result.predict(X=df_mp)))\ndf_mp['entries'] = df_v2['entries']\n\nprint('accuracy_score:\\nnormalize_true = {:f} \\nnormalize_false = {:f}'.format(\n    accuracy_score(df_mp['entries_new'], df_mp['entries']),\n    accuracy_score(df_mp['entries_new'], df_mp['entries'], normalize=False)\n    ))"],"metadata":{},"outputs":[],"execution_count":34},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":35}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.6.5","nbconvert_exporter":"python","file_extension":".py"},"name":"poc-ny-subway","notebookId":1932292055738400},"nbformat":4,"nbformat_minor":0}
